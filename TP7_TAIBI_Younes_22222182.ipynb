{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd264e46",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage profond - TP 7 (DM 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320cead7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchinfo\n",
    "from torch.nn import Sequential, Conv2d, BatchNorm2d, ReLU, MaxPool2d, Linear\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057172ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return t.mean(x, dim=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3728ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b48f894",
   "metadata": {},
   "source": [
    "## ResNet architecture (Q1-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(in_feats, out_feats, kernel_size=3, stride=first_stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_feats),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_feats, out_feats, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_feats)\n",
    "        )\n",
    "\n",
    "        if first_stride == 1:\n",
    "            self.right = nn.Identity()  \n",
    "        else:\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Conv2d(in_feats, out_feats, kernel_size=1, stride=first_stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_feats)\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        left_output = self.left(x)\n",
    "        right_output = self.right(x)\n",
    "        output = left_output + right_output\n",
    "        return self.relu(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockGroup(nn.Module):\n",
    "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
    "        \"\"\"Un groupe de n_blocks ResidualBlock, où seul le premier bloc utilise le first_stride donné.\"\"\"\n",
    "        super().__init__()\n",
    "        blocks = [ResidualBlock(in_feats, out_feats, first_stride)]\n",
    "\n",
    "        for _ in range(1, n_blocks):\n",
    "            blocks.append(ResidualBlock(out_feats, out_feats, first_stride=1))\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.blocks(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ff56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_blocks_per_group: list[int], out_features_per_group: list[int], first_strides_per_group: list[int], n_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(n_blocks_per_group) == len(out_features_per_group) == len(first_strides_per_group), \\\n",
    "            \"Les listes n_blocks_per_group, out_features_per_group et first_strides_per_group doivent avoir la même longueur.\"\n",
    "\n",
    "        self.in_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False), \n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1) \n",
    "        )\n",
    "\n",
    "        self.residual_layers = nn.ModuleList()\n",
    "        in_feats = 64 \n",
    "        for n_blocks, out_feats, first_stride in zip(n_blocks_per_group, out_features_per_group, first_strides_per_group):\n",
    "            group = BlockGroup(n_blocks, in_feats, out_feats, first_stride)\n",
    "            self.residual_layers.append(group)\n",
    "            in_feats = out_feats  \n",
    "\n",
    "        self.out_layers = nn.Sequential(\n",
    "            AveragePool(),  \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(in_feats, n_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.in_layers(x)\n",
    "\n",
    "        for group in self.residual_layers:\n",
    "            x = group(x)\n",
    "        x = self.out_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3591e1cb",
   "metadata": {},
   "source": [
    "# (a) Pourquoi les shapes doivent être identiques ?\n",
    "# L'addition des deux branches nécessite que leurs shapes soient identiques. Sinon, l'opération d'addition ne serait pas possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7350c9",
   "metadata": {},
   "source": [
    "# (b) Pourquoi désactiver le biais dans les convolutions ?\n",
    "\n",
    "#  car la couche BatchNorm qui suit ajoute déjà un biais. Cela évite la redondance et aide le modèle à mieux apprendre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87687660",
   "metadata": {},
   "source": [
    "## Testing (Q3-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a3ad0",
   "metadata": {},
   "source": [
    "# test residual block :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7310f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_residual_block():\n",
    "    x = t.randn(1, 64, 32, 32)\n",
    "\n",
    "    block = ResidualBlock(in_feats=64, out_feats=64, first_stride=1)\n",
    "    output = block(x)\n",
    "    print(\"Shape sans downsampling:\", output.shape)  # Doit être (1, 64, 32, 32)\n",
    "    assert output.shape == (1, 64, 32, 32), \"Erreur de shape sans downsampling\"\n",
    "\n",
    "    block = ResidualBlock(in_feats=64, out_feats=128, first_stride=2)\n",
    "    output = block(x)\n",
    "    print(\"Shape avec downsampling:\", output.shape)  # Doit être (1, 128, 16, 16)\n",
    "    assert output.shape == (1, 128, 16, 16), \"Erreur de shape avec downsampling\"\n",
    "\n",
    "test_residual_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e143f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_block_group():\n",
    "    x = t.randn(1, 64, 32, 32) \n",
    "\n",
    "    group = BlockGroup(n_blocks=2, in_feats=64, out_feats=128, first_stride=2)\n",
    "    output = group(x)\n",
    "    print(\"Shape de BlockGroup:\", output.shape) \n",
    "    assert output.shape == (1, 128, 16, 16), \"Erreur de shape de BlockGroup\"\n",
    "\n",
    "test_block_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_resnet():\n",
    "    x = t.randn(1, 3, 224, 224) \n",
    "\n",
    "    n_blocks_per_group = [3, 4, 6, 3]\n",
    "    out_features_per_group = [64, 128, 256, 512]\n",
    "    first_strides_per_group = [1, 2, 2, 2]\n",
    "    n_classes = 1000  \n",
    "    model = ResNet(n_blocks_per_group, out_features_per_group, first_strides_per_group, n_classes)\n",
    "    output = model(x)\n",
    "    print(\"Shape de ResNet:\", output.shape) \n",
    "    assert output.shape == (1, 1000), \"Erreur de shape de ResNet\"\n",
    "\n",
    "test_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_my_resnet34():\n",
    "    return ResNet(n_blocks_per_group=[3, 4, 6, 3], out_features_per_group=[64, 128, 256, 512], first_strides_per_group=[1, 2, 2, 2], n_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b71fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resnet = initialize_my_resnet34()\n",
    "target_resnet = models.resnet34()\n",
    "print(\"My model:\", torchinfo.summary(my_resnet, input_size=(1, 3, 64, 64), depth=4), sep=\"\\n\")\n",
    "print(\"Reference model:\", torchinfo.summary(target_resnet, input_size=(1, 3, 64, 64), depth=2), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b8d44",
   "metadata": {},
   "source": [
    "## Inference (Q6-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_weights(my_resnet, pretrained_resnet):\n",
    "    mydict = my_resnet.state_dict()\n",
    "    pretraineddict = pretrained_resnet.state_dict()\n",
    "    assert len(mydict) == len(pretraineddict), \"Mismatching state dictionaries.\"\n",
    "    state_dict_to_load = {mykey: pretrainedvalue for (mykey, _), (_, pretrainedvalue) in zip(mydict.items(), pretraineddict.items())}\n",
    "    my_resnet.load_state_dict(state_dict_to_load)\n",
    "    return my_resnet\n",
    "\n",
    "\n",
    "pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1).to(device)\n",
    "my_resnet = copy_weights(my_resnet, pretrained_resnet).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "IMAGENET_TRANSFORM = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(model, image_tensor):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "        _, predicted_class = torch.max(probabilities, dim=0)\n",
    "    return predicted_class.item()\n",
    "\n",
    "for i in range(3):\n",
    "    image_tensor = torch.rand(1, 3, 224, 224).to(device)\n",
    "\n",
    "    pred_torch = predict(pretrained_resnet, image_tensor)\n",
    "    pred_my = predict(my_resnet, image_tensor)\n",
    "\n",
    "    print(f\"Image aléatoire {i + 1}\")\n",
    "    print(f\"Prédiction de torch_resnet: {pred_torch}\")\n",
    "    print(f\"Prédiction de my_resnet: {pred_my}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72420e",
   "metadata": {},
   "source": [
    "## Finetuning (Q8-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3358bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_for_finetuning(n_classes: int):\n",
    "    my_resnet = initialize_my_resnet34()\n",
    "\n",
    "    pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "    my_resnet = copy_weights(my_resnet, pretrained_resnet).to(device)\n",
    "\n",
    "    for param in my_resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    in_features = my_resnet.out_layers[-1].in_features\n",
    "    my_resnet.out_layers[-1] = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    return my_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar() -> tuple[datasets.CIFAR10, datasets.CIFAR10]:\n",
    "    cifar_trainset = datasets.CIFAR10(\"datasets\", train=True, download=True, transform=IMAGENET_TRANSFORM)\n",
    "    cifar_testset = datasets.CIFAR10(\"datasets\", train=False, download=True, transform=IMAGENET_TRANSFORM)\n",
    "    return cifar_trainset, cifar_testset\n",
    "\n",
    "def get_cifar_subset(trainset_size: int = 10_000, testset_size: int = 1_000) -> tuple[Subset, Subset]:\n",
    "    cifar_trainset, cifar_testset = get_cifar()\n",
    "    return Subset(cifar_trainset, range(trainset_size)), Subset(cifar_testset, range(testset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_to_cifar(model, batch_size=64, epochs=1, learning_rate=1e-3):\n",
    "    trainset, testset = get_cifar()\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    params_to_optimize = model.out_layers[-1].parameters()\n",
    "    optimizer = t.optim.Adam(params_to_optimize, lr=learning_rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(trainloader)\n",
    "        train_acc = 100. * correct / total\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        test_loss = running_loss / len(testloader)\n",
    "        test_acc = 100. * correct / total\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_resnet_for_finetuning(n_classes=10).to(device)\n",
    "model = finetune_to_cifar(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace0d2d8",
   "metadata": {},
   "source": [
    "# Pourquoi la précision est-elle nettement meilleure dans le premier cas ?\n",
    "#  Sans copie du poids de modele jai eu 15 %. car le modele  est initialisé avec des poids aleatoire ce qui entraine une lente convergence, pour cela on a besoin de plus de donnees(cifar 50000 !) et plus d epochs pour avoir une bonne precision alors que le modele avec poids est pre-entrainé avec un jeu de donnees plus large ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1627c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
